{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, polynomial functions and kernel functions are closely related, especially in the context of Support Vector Machines (SVMs). SVMs are used for both classification and regression tasks. They aim to find a hyperplane that best separates the data points while maximizing the margin.\n",
    "\n",
    "Polynomial kernel functions are a type of kernel function used in SVMs. They allow the SVM to implicitly compute the dot product of data points in a higher-dimensional space without explicitly transforming the data into that space. The polynomial kernel is defined as K(x, y) = (x⋅y + c)^d, where 'd' is the degree of the polynomial and 'c' is a constant. This kernel calculates the similarity between two data points in a feature space.\n",
    "\n",
    "The polynomial kernel can be seen as a way of capturing complex relationships between features by creating polynomial combinations of the original feature dimensions. This can be helpful when the data is not linearly separable in the original feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "X = your_training_data\n",
    "y = your_labels\n",
    "svm = SVC(kernel='poly', degree=3)  # Use a polynomial kernel of degree 3\n",
    "svm.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Support Vector Regression (SVR), epsilon (ε) defines a margin within which errors are tolerated. Data points that fall within this margin are not considered as support vectors. Increasing the value of epsilon generally leads to fewer support vectors, as a larger margin allows more data points to be within the margin without affecting the loss function. This can lead to a more lenient regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vectr Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choice of Kernel Function: Different kernel functions (linear, polynomial, radial basis function, etc.) are suited for different types of data and relationships. For example, if you suspect a non-linear relationship, using a polynomial or radial basis function kernel might be appropriate.\n",
    "\n",
    "C Parameter: The C parameter trades off between achieving a low training error and a low testing error. Smaller values of C create a wider margin, which might lead to more generalized models but might allow more errors in the training data.\n",
    "\n",
    "Epsilon (ε) Parameter: As mentioned earlier, increasing epsilon leads to a wider margin, which can result in fewer support vectors and a more relaxed fit to the training data.\n",
    "\n",
    "Gamma Parameter: This parameter affects the shape of the decision boundary. A small gamma will result in a more generalization, while a large gamma will lead to a tighter fit, possibly resulting in overfitting. Gamma defines how far the influence of a single training example reaches.\n",
    "\n",
    "The choice of these parameters greatly depends on the specific problem, data, and desired model complexity. It's important to use techniques like cross-validation to find the optimal values that work well for your specific problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You can use any dataset of your choice for this assignment, but make sure it is suitable for classification and has a sufficient number of features and samples"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q5. Assignment:\n",
    "L Import the necessary libraries and load the dataseg\n",
    "L Split the dataset into training and testing setZ\n",
    "L Preprocess the data using any technique of your choice (e.g. scaling, normaliMationK\n",
    "L Create an instance of the SVC classifier and train it on the training datW\n",
    "L hse the trained classifier to predict the labels of the testing datW\n",
    "L Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,\n",
    "precision, recall, F1-scoreK\n",
    "L Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to\n",
    "improve its performanc_\n",
    "L Train the tuned classifier on the entire dataseg\n",
    "L Save the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Best Parameters: {'C': 10, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "Best Cross-Validation Accuracy: 0.9583333333333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svm_classifier.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create an instance of the SVC classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use the trained classifier to predict the labels of the testing data\n",
    "y_pred = svm_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance using accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Tune hyperparameters using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'poly', 'rbf'], 'gamma': [0.1, 1, 'scale', 'auto']}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "best_svm_classifier = grid_search.best_estimator_\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Train the tuned classifier on the entire dataset\n",
    "best_svm_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save the trained classifier to a file using joblib\n",
    "joblib.dump(best_svm_classifier, 'svm_classifier.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
